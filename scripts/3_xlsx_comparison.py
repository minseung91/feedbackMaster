#!/usr/bin/env python3
"""
preprocessed í´ë” ë‚´ XLSX íŒŒì¼ë“¤ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ 
ê° íŒŒì¼ë³„ë¡œ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•˜ê³  ë²ˆì—­ê²€ìˆ˜/ì‹ìë²ˆì—­ê²€ìˆ˜ ê²°ê³¼ë¥¼ ë¶„ë¦¬ ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import pandas as pd
import os
import sys
import glob
from pathlib import Path
import difflib
import jiwer
import re
from typing import Tuple, List

def calculate_cer(reference: str, hypothesis: str) -> float:
    """
    Character Error Rate (CER) ê³„ì‚°
    
    Args:
        reference (str): ì°¸ì¡° í…ìŠ¤íŠ¸ (target)
        hypothesis (str): ë¹„êµ í…ìŠ¤íŠ¸ (val)
        
    Returns:
        float: CER ê°’ (0.0 ~ 1.0)
    """
    if not reference or not hypothesis:
        return 1.0 if reference != hypothesis else 0.0
    
    # ë¬¸ì ë‹¨ìœ„ë¡œ ë¶„í• 
    ref_chars = list(str(reference))
    hyp_chars = list(str(hypothesis))
    
    # í¸ì§‘ ê±°ë¦¬ ê³„ì‚°
    d = [[0 for _ in range(len(hyp_chars) + 1)] for _ in range(len(ref_chars) + 1)]
    
    for i in range(len(ref_chars) + 1):
        d[i][0] = i
    for j in range(len(hyp_chars) + 1):
        d[0][j] = j
    
    for i in range(1, len(ref_chars) + 1):
        for j in range(1, len(hyp_chars) + 1):
            if ref_chars[i-1] == hyp_chars[j-1]:
                d[i][j] = d[i-1][j-1]
            else:
                d[i][j] = min(d[i-1][j] + 1,      # ì‚­ì œ
                             d[i][j-1] + 1,       # ì‚½ì…
                             d[i-1][j-1] + 1)     # ì¹˜í™˜
    
    return d[len(ref_chars)][len(hyp_chars)] / len(ref_chars)

def calculate_wer(reference: str, hypothesis: str) -> float:
    """
    Word Error Rate (WER) ê³„ì‚°
    
    Args:
        reference (str): ì°¸ì¡° í…ìŠ¤íŠ¸ (target)
        hypothesis (str): ë¹„êµ í…ìŠ¤íŠ¸ (val)
        
    Returns:
        float: WER ê°’ (0.0 ~ 1.0)
    """
    if not reference or not hypothesis:
        return 1.0 if reference != hypothesis else 0.0
    
    try:
        return jiwer.wer(str(reference), str(hypothesis))
    except:
        # jiwer ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ë‹¨ì–´ ê¸°ë°˜ ê³„ì‚°
        ref_words = str(reference).split()
        hyp_words = str(hypothesis).split()
        
        if len(ref_words) == 0:
            return 0.0 if len(hyp_words) == 0 else 1.0
        
        # ê°„ë‹¨í•œ ë‹¨ì–´ ë‹¨ìœ„ í¸ì§‘ ê±°ë¦¬
        d = [[0 for _ in range(len(hyp_words) + 1)] for _ in range(len(ref_words) + 1)]
        
        for i in range(len(ref_words) + 1):
            d[i][0] = i
        for j in range(len(hyp_words) + 1):
            d[0][j] = j
        
        for i in range(1, len(ref_words) + 1):
            for j in range(1, len(hyp_words) + 1):
                if ref_words[i-1] == hyp_words[j-1]:
                    d[i][j] = d[i-1][j-1]
                else:
                    d[i][j] = min(d[i-1][j] + 1,      # ì‚­ì œ
                                 d[i][j-1] + 1,       # ì‚½ì…
                                 d[i-1][j-1] + 1)     # ì¹˜í™˜
        
        return d[len(ref_words)][len(hyp_words)] / len(ref_words)


def calculate_translation_metrics(translation_rows: pd.DataFrame, all_df: pd.DataFrame) -> dict:
    """
    ë²ˆì—­ê²€ìˆ˜ ê²°ê³¼ì— ëŒ€í•œ ì „ì²´ ë©”íŠ¸ë¦­ ê³„ì‚° (ì „ì²´ ê³ ìœ  í…ìŠ¤íŠ¸ë°•ìŠ¤ ê¸°ì¤€)
    
    Args:
        translation_rows (DataFrame): ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒ í–‰ë“¤
        all_df (DataFrame): ì „ì²´ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        dict: ê³„ì‚°ëœ ë©”íŠ¸ë¦­ë“¤
    """
    if 'file_name' not in all_df.columns or 'text_box_order' not in all_df.columns:
        # ì¹¼ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        if len(translation_rows) == 0:
            return {
                'total_pairs': 0,
                'unique_textboxes': 0,
                'cell_avg_cer': 0.0,
                'cell_avg_wer': 0.0,
                'overall_cer': 0.0,
                'overall_wer': 0.0,
                'cer_scores': [],
                'wer_scores': []
            }
        unique_rows = translation_rows
        all_target_text = []
        all_val_text = []
        cer_scores = []
        wer_scores = []
        
        for _, row in unique_rows.iterrows():
            target = str(row['target']) if pd.notna(row['target']) else ""
            val = str(row['val']) if pd.notna(row['val']) else ""
            
            cer = calculate_cer(target, val)
            wer = calculate_wer(target, val)
            
            cer_scores.append(cer)
            wer_scores.append(wer)
            all_target_text.append(target)
            all_val_text.append(val)
    else:
        # ì „ì²´ ê³ ìœ  í…ìŠ¤íŠ¸ë°•ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        # 1. ì „ì²´ ê³ ìœ  í…ìŠ¤íŠ¸ë°•ìŠ¤ ëª©ë¡ ìƒì„±
        all_unique_textboxes = all_df.groupby(['file_name', 'text_box_order']).first().reset_index()
        
        # 2. ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒ í…ìŠ¤íŠ¸ë°•ìŠ¤ë“¤ (ì¤‘ë³µ ì œê±°)
        if len(translation_rows) > 0:
            translation_unique = translation_rows.groupby(['file_name', 'text_box_order']).first().reset_index()
            # ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒ í…ìŠ¤íŠ¸ë°•ìŠ¤ë“¤ì„ dictë¡œ ë³€í™˜ (ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•´)
            translation_dict = {}
            for _, row in translation_unique.iterrows():
                key = (row['file_name'], row['text_box_order'])
                translation_dict[key] = row
        else:
            translation_dict = {}
        
        cer_scores = []
        wer_scores = []
        all_target_text = []
        all_val_text = []
        
        # 3. ëª¨ë“  ê³ ìœ  í…ìŠ¤íŠ¸ë°•ìŠ¤ì— ëŒ€í•´ CER/WER ê³„ì‚°
        for _, row in all_unique_textboxes.iterrows():
            key = (row['file_name'], row['text_box_order'])
            
            if key in translation_dict:
                # ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒì¸ ê²½ìš°: ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
                translation_row = translation_dict[key]
                target = str(translation_row['target']) if pd.notna(translation_row['target']) else ""
                val = str(translation_row['val']) if pd.notna(translation_row['val']) else ""
            else:
                # ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒì´ ì•„ë‹Œ ê²½ìš°: target = val (ìˆ˜ì •ë˜ì§€ ì•ŠìŒ)
                target = str(row['target']) if pd.notna(row['target']) else ""
                val = target  # ìˆ˜ì •ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ë™ì¼
            
            # CER/WER ê³„ì‚°
            cer = calculate_cer(target, val)
            wer = calculate_wer(target, val)
            
            cer_scores.append(cer)
            wer_scores.append(wer)
            all_target_text.append(target)
            all_val_text.append(val)
    
    # ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ì¤€ CER/WER ê³„ì‚°
    combined_target = " ".join(all_target_text)
    combined_val = " ".join(all_val_text)
    
    overall_cer = calculate_cer(combined_target, combined_val)
    overall_wer = calculate_wer(combined_target, combined_val)
    
    return {
        'total_pairs': len(translation_rows),  # ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒ ì›ë³¸ í–‰ ìˆ˜
        'unique_textboxes': len(all_target_text),  # ì „ì²´ ê³ ìœ  í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜
        'modified_textboxes': len([cer for cer in cer_scores if cer > 0]),  # ì‹¤ì œ ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜
        'cell_avg_cer': sum(cer_scores) / len(cer_scores) if cer_scores else 0.0,
        'cell_avg_wer': sum(wer_scores) / len(wer_scores) if wer_scores else 0.0,
        'overall_cer': overall_cer,
        'overall_wer': overall_wer,
        'cer_scores': cer_scores,
        'wer_scores': wer_scores
    }

def merge_feedback_v2_comments(df):
    """
    ë™ì¼í•œ target-val ì„¸íŠ¸ì— ëŒ€í•´ ì—¬ëŸ¬ ê°œì˜ FEEDBACK_V2 í–‰ì´ ìˆìœ¼ë©´ 
    commentë¥¼ í•©ì³ì„œ í•˜ë‚˜ë¡œ í†µí•©
    
    Args:
        df (DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        DataFrame: FEEDBACK_V2 commentê°€ í†µí•©ëœ ë°ì´í„°í”„ë ˆì„
    """
    # FEEDBACK_V2ê°€ ì•„ë‹Œ í–‰ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    non_feedback_v2 = df[df['type'] != 'FEEDBACK_V2'].copy()
    
    # FEEDBACK_V2 í–‰ë“¤ë§Œ ì¶”ì¶œ
    feedback_v2_rows = df[df['type'] == 'FEEDBACK_V2'].copy()
    
    if len(feedback_v2_rows) == 0:
        return df
    
    # target-val ìŒë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ comment í†µí•©
    merged_feedback_v2 = []
    
    # target-val ìŒë³„ë¡œ ê·¸ë£¹í™”
    grouped = feedback_v2_rows.groupby(['target', 'val'])
    
    for (target, val), group in grouped:
        if len(group) == 1:
            # ë‹¨ì¼ í–‰ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì¶”ê°€
            merged_feedback_v2.append(group.iloc[0])
        else:
            # ì—¬ëŸ¬ í–‰ì¸ ê²½ìš° comment í†µí•©
            base_row = group.iloc[0].copy()
            
            # commentë“¤ì„ ìˆ˜ì§‘ (ë¹„ì–´ìˆì§€ ì•Šì€ ê²ƒë§Œ)
            comments = []
            for _, row in group.iterrows():
                comment = row['comment']
                if pd.notna(comment) and str(comment).strip() != '':
                    comments.append(str(comment).strip())
            
            # comment í†µí•© (êµ¬ë¶„ì: " | ")
            if comments:
                base_row['comment'] = " | ".join(comments)
            
            merged_feedback_v2.append(base_row)
    
    # í†µí•©ëœ FEEDBACK_V2 ë°ì´í„°í”„ë ˆì„ ìƒì„±
    if merged_feedback_v2:
        merged_feedback_v2_df = pd.DataFrame(merged_feedback_v2)
        # ì›ë˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ê¸° ìœ„í•´ ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        merged_feedback_v2_df = merged_feedback_v2_df.sort_index()
    else:
        merged_feedback_v2_df = pd.DataFrame(columns=df.columns)
    
    # ì „ì²´ ë°ì´í„°í”„ë ˆì„ ì¬êµ¬ì„±
    result_df = pd.concat([non_feedback_v2, merged_feedback_v2_df], ignore_index=True)
    
    return result_df

def filter_empty_target_rows(df):
    """
    targetì´ ë¹„ì–´ìˆëŠ” í–‰ë“¤ì„ ë”°ë¡œ ë¶„ë¦¬
    
    Args:
        df (DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        tuple: (ë¹„êµí•  ë°ì´í„°í”„ë ˆì„, targetì´ ë¹„ì–´ìˆëŠ” ë°ì´í„°í”„ë ˆì„)
    """
    # targetì´ ë¹„ì–´ìˆëŠ” í–‰ë“¤ (NaN ë˜ëŠ” ë¹ˆ ë¬¸ìì—´)
    empty_target_mask = df['target'].isna() | (df['target'] == '') | (df['target'].astype(str).str.strip() == '')
    
    empty_target_rows = df[empty_target_mask].copy()
    valid_target_rows = df[~empty_target_mask].copy()
    
    return valid_target_rows, empty_target_rows

def remove_duplicates_with_feedback_v2(df):
    """
    FEEDBACK_V2 íƒ€ì…ê³¼ ë™ì¼í•œ target, val ê°’ì„ ê°€ì§€ì§€ë§Œ 
    type, operation, commentê°€ ë¹„ì–´ìˆëŠ” ì¤‘ë³µ í–‰ë“¤ì„ ì œê±°
    
    Args:
        df (DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        DataFrame: ì¤‘ë³µì´ ì œê±°ëœ ë°ì´í„°í”„ë ˆì„
    """
    # FEEDBACK_V2 íƒ€ì…ì¸ í–‰ë“¤ì˜ target, val ê°’ë“¤ì„ ìˆ˜ì§‘
    feedback_v2_rows = df[df['type'] == 'FEEDBACK_V2']
    feedback_v2_pairs = set()
    
    for _, row in feedback_v2_rows.iterrows():
        target_val = (row['target'], row['val'])
        feedback_v2_pairs.add(target_val)
    
    # ì œê±°í•  ì¤‘ë³µ í–‰ë“¤ì„ ì°¾ê¸°
    duplicate_indices = []
    
    for idx, row in df.iterrows():
        # FEEDBACK_V2ê°€ ì•„ë‹Œ í–‰ë“¤ ì¤‘ì—ì„œ
        if row['type'] != 'FEEDBACK_V2':
            target_val = (row['target'], row['val'])
            
            # FEEDBACK_V2ì™€ ë™ì¼í•œ (target, val) ìŒì´ê³ 
            if target_val in feedback_v2_pairs:
                # type, operation, commentê°€ ëª¨ë‘ ë¹„ì–´ìˆê±°ë‚˜ NaNì¸ ê²½ìš°
                is_empty_type = pd.isna(row['type']) or row['type'] == ''
                is_empty_operation = pd.isna(row['operation']) or row['operation'] == ''
                is_empty_comment = pd.isna(row['comment']) or row['comment'] == ''
                
                if is_empty_type and is_empty_operation and is_empty_comment:
                    duplicate_indices.append(idx)
    
    # ì¤‘ë³µ í–‰ë“¤ ì œê±°
    cleaned_df = df.drop(duplicate_indices).reset_index(drop=True)
    
    return cleaned_df

def get_original_different_rows(df, output_columns):
    """
    FEEDBACK_V2ê°€ í†µí•©ë˜ì§€ ì•Šì€ ì›ë³¸ ë°ì´í„°ì—ì„œ targetê³¼ valì´ ë‹¤ë¥¸ í–‰ë“¤ì„ ì°¾ìŒ
    
    Args:
        df (DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„ (FEEDBACK_V2 í†µí•© ì „)
        output_columns (list): ì¶œë ¥í•  ì¹¼ëŸ¼ë“¤
        
    Returns:
        DataFrame: targetê³¼ valì´ ë‹¤ë¥¸ í–‰ë“¤
    """
    # targetê³¼ val ì¹¼ëŸ¼ ë¹„êµ (exact match)
    # NaN ê°’ë„ ê³ ë ¤í•˜ì—¬ ë¹„êµ
    different_rows = df[df['target'] != df['val']]
    
    # NaN ê°’ì´ ë‘˜ ë‹¤ ìˆëŠ” ê²½ìš°ëŠ” ê°™ì€ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
    both_nan = df['target'].isna() & df['val'].isna()
    different_rows = df[~both_nan & (df['target'] != df['val'])]
    
    return different_rows

def process_single_file(file_path, output_dir):
    """
    ë‹¨ì¼ XLSX íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ë²ˆì—­ê²€ìˆ˜/ì‹ìë²ˆì—­ê²€ìˆ˜ ê²°ê³¼ë¥¼ ë¶„ë¦¬ ì €ì¥
    
    Args:
        file_path (str): ì²˜ë¦¬í•  XLSX íŒŒì¼ ê²½ë¡œ
        output_dir (str): ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
    
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ í†µê³„
    """
    try:
        print(f"ğŸ“– íŒŒì¼ ì²˜ë¦¬ ì¤‘: {os.path.basename(file_path)}")
        
        # XLSX íŒŒì¼ ì½ê¸°
        df = pd.read_excel(file_path)
        
        # í•„ìš”í•œ ì¹¼ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        required_columns = ['target', 'val']
        output_columns = ['target', 'val', 'type', 'operation', 'comment', 'tag', 'file_name', 'text_box_order']
        
        missing_required = [col for col in required_columns if col not in df.columns]
        if missing_required:
            print(f"âŒ ì˜¤ë¥˜: í•„ìˆ˜ ì¹¼ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_required}")
            return None
        
        # ì¡´ì¬í•˜ëŠ” ì¹¼ëŸ¼ë§Œ ì‚¬ìš©
        output_columns = [col for col in output_columns if col in df.columns]
        
        # 1ë‹¨ê³„: FEEDBACK_V2 comment í†µí•©
        df_merged = merge_feedback_v2_comments(df)
        
        # 2ë‹¨ê³„: targetì´ ë¹„ì–´ìˆëŠ” í–‰ë“¤ ë¶„ë¦¬
        df_valid_target, df_empty_target = filter_empty_target_rows(df_merged)
        
        # 3ë‹¨ê³„: FEEDBACK_V2ì™€ ì¤‘ë³µë˜ëŠ” ë¹ˆ í–‰ë“¤ ì œê±° (targetì´ ìœ íš¨í•œ í–‰ë“¤ë§Œ)
        df_cleaned = remove_duplicates_with_feedback_v2(df_valid_target)
        
        # targetê³¼ val ì¹¼ëŸ¼ ë¹„êµ (exact match)
        both_nan = df_cleaned['target'].isna() & df_cleaned['val'].isna()
        different_rows = df_cleaned[~both_nan & (df_cleaned['target'] != df_cleaned['val'])]
        
        if len(different_rows) == 0:
            print(f"âœ… {os.path.basename(file_path)}: targetê³¼ valì´ ëª¨ë‘ ì¼ì¹˜í•©ë‹ˆë‹¤.")
            
            # ê³ ìœ í•œ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜ ê³„ì‚° (ì¼ì¹˜í•˜ëŠ” ê²½ìš°ì—ë„) - ì •ë¦¬ëœ ë°ì´í„° ê¸°ì¤€
            if 'file_name' in df_cleaned.columns and 'text_box_order' in df_cleaned.columns:
                unique_textboxes_count = len(df_cleaned.groupby(['file_name', 'text_box_order']))
            else:
                unique_textboxes_count = len(df_cleaned)
            
            return {
                'file_name': os.path.basename(file_path),
                'total_data_rows': len(df),
                'unique_textboxes': unique_textboxes_count,
                'different_rows': 0,
                'translation_rows': 0,
                'typography_rows': 0
            }
        
        # operationì— ë”°ë¼ ë¶„ë¦¬
        typography_operation = "ì‹ìë²ˆì—­ê²€ìˆ˜(ì›¹íˆ°)"
        translation_rows = different_rows[different_rows['operation'] != typography_operation]
        
        # ë²ˆì—­ê²€ìˆ˜ ê²°ê³¼ (í•„í„°ë§ ì—†ì´ ëª¨ë“  ë³€ê²½ì‚¬í•­ í¬í•¨)
        translation_rows_filtered = translation_rows
        print(f"   ğŸ“Š ë²ˆì—­ê²€ìˆ˜ ê²°ê³¼: {len(translation_rows_filtered)}í–‰ (ëª¨ë“  ë³€ê²½ì‚¬í•­ í¬í•¨)")
        
        # ë²ˆì—­ê²€ìˆ˜ ê²°ê³¼ ì €ì¥ (FEEDBACK_V2 í†µí•©ëœ ë²„ì „)
        if len(translation_rows_filtered) > 0:
            translation_file = os.path.join(output_dir, "translation_review.csv")
            translation_rows_filtered[output_columns].to_csv(translation_file, index=False, encoding='utf-8-sig')
            print(f"   ğŸ“ ë²ˆì—­ê²€ìˆ˜ ê²°ê³¼ ì €ì¥: {len(translation_rows_filtered)}í–‰")
            
            # ë²ˆì—­ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° (ì „ì²´ ê³ ìœ  í…ìŠ¤íŠ¸ë°•ìŠ¤ ê¸°ì¤€)
            metrics = calculate_translation_metrics(translation_rows_filtered, df_cleaned)
            
            # ë²ˆì—­ í†µê³„ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
            metrics_file = os.path.join(output_dir, "translation_statistics.txt")
            
        # ì „ì²´ í–‰ ìˆ˜ì™€ ìˆ˜ì • ë¹„ìœ¨ ê³„ì‚°
        # file_nameê³¼ text_box_order ê¸°ì¤€ìœ¼ë¡œ ê³ ìœ í•œ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜ ê³„ì‚°
        # ì •ë¦¬ëœ ë°ì´í„°(df_cleaned) ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
        if 'file_name' in df_cleaned.columns and 'text_box_order' in df_cleaned.columns:
            unique_textboxes = df_cleaned.groupby(['file_name', 'text_box_order']).size()
            total_unique_textboxes = len(unique_textboxes)
        else:
            # ì¹¼ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            total_unique_textboxes = len(df_cleaned)
        
        total_data_rows = len(df)  # ì „ì²´ ë°ì´í„° í–‰ ìˆ˜ (ì°¸ê³ ìš©)
        total_different_rows = len(different_rows)
        filtered_translation_rows = len(translation_rows_filtered)  # ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒ í–‰ ìˆ˜
        
        # ìˆ˜ì • ë¹„ìœ¨ì€ ê³ ìœ í•œ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜ ëŒ€ë¹„ë¡œ ê³„ì‚°
        modification_ratio = (filtered_translation_rows / total_unique_textboxes * 100) if total_unique_textboxes > 0 else 0
        
        with open(metrics_file, 'w', encoding='utf-8') as f:
            f.write(f"ë²ˆì—­ í’ˆì§ˆ ë©”íŠ¸ë¦­ - {os.path.basename(file_path)}\n")
            f.write("=" * 50 + "\n\n")
            
            # ê²€ìˆ˜ëœ í…ìŠ¤íŠ¸ë°•ìŠ¤ ë¹„ìœ¨ ê³„ì‚° (ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒ í–‰ ìˆ˜ / ì „ì²´ í…ìŠ¤íŠ¸ë°•ìŠ¤)
            if filtered_translation_rows > 0:
                reviewed_ratio = (filtered_translation_rows / total_unique_textboxes * 100) if total_unique_textboxes > 0 else 0
                
                f.write("ğŸ“Š ì „ì²´ í†µê³„:\n")
                f.write(f"  - ì „ì²´ ì‹¤ì§ˆ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜: {total_unique_textboxes:,}ê°œ\n")
                f.write(f"  - ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒ í–‰ ìˆ˜: {filtered_translation_rows}ê°œ\n")
                f.write(f"  - ìˆ˜ì •ë˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ë°•ìŠ¤: {metrics['unique_textboxes'] - metrics['modified_textboxes']}ê°œ\n")
                f.write(f"  - ê²€ìˆ˜ëœ í…ìŠ¤íŠ¸ë°•ìŠ¤ ë¹„ìœ¨: {reviewed_ratio:.2f}%\n\n")
                
                f.write("ğŸ“ˆ ë²ˆì—­ í’ˆì§ˆ ë©”íŠ¸ë¦­ (ì „ì²´ ê³ ìœ  í…ìŠ¤íŠ¸ë°•ìŠ¤ ê¸°ì¤€):\n\n")
                f.write(f"ì „ì²´ í…ìŠ¤íŠ¸ë°•ìŠ¤ í‰ê· :\n")
                f.write(f"  - í‰ê·  CER: {metrics['cell_avg_cer']:.4f} ({metrics['cell_avg_cer']*100:.2f}%)\n")
                f.write(f"  - í‰ê·  WER: {metrics['cell_avg_wer']:.4f} ({metrics['cell_avg_wer']*100:.2f}%)\n\n")
                f.write(f"ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ì¤€:\n")
                f.write(f"  - ì „ì²´ CER: {metrics['overall_cer']:.4f} ({metrics['overall_cer']*100:.2f}%)\n")
                f.write(f"  - ì „ì²´ WER: {metrics['overall_wer']:.4f} ({metrics['overall_wer']*100:.2f}%)\n")
            else:
                f.write("ğŸ“Š ì „ì²´ í†µê³„:\n")
                f.write(f"  - ì „ì²´ ì‹¤ì§ˆ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜: {total_unique_textboxes:,}ê°œ\n")
                f.write(f"  - ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒ í–‰ ìˆ˜: 0ê°œ\n")
                f.write(f"  - ìˆ˜ì •ë˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ë°•ìŠ¤: {total_unique_textboxes}ê°œ\n")
                f.write(f"  - ê²€ìˆ˜ëœ í…ìŠ¤íŠ¸ë°•ìŠ¤ ë¹„ìœ¨: 0.00%\n\n")
                f.write("ğŸ“ˆ ë²ˆì—­ í’ˆì§ˆ ë©”íŠ¸ë¦­: í•´ë‹¹ ì—†ìŒ (ë²ˆì—­ê²€ìˆ˜ ëŒ€ìƒ ì—†ìŒ)\n")
        
        # ì‹ìë²ˆì—­ê²€ìˆ˜ ê²°ê³¼ ì €ì¥ (FEEDBACK_V2 ë¶„ë¦¬ëœ ì›ë³¸ ë²„ì „)
        df_valid_target_cleaned = remove_duplicates_with_feedback_v2(df_valid_target)
        original_different_rows = get_original_different_rows(df_valid_target_cleaned, output_columns)
        typography_rows_original = original_different_rows[original_different_rows['operation'] == typography_operation]
        
        if len(typography_rows_original) > 0:
            typography_file = os.path.join(output_dir, "typesetting_review.csv")
            typography_rows_original[output_columns].to_csv(typography_file, index=False, encoding='utf-8-sig')
            print(f"   ğŸ¨ ì‹ìë²ˆì—­ê²€ìˆ˜ ê²°ê³¼ ì €ì¥: {len(typography_rows_original)}í–‰")
        
        # ê³ ìœ í•œ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜ ê³„ì‚° (ë°˜í™˜ìš©) - ì •ë¦¬ëœ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì¼ê´€ì„± ìœ ì§€
        if 'file_name' in df_cleaned.columns and 'text_box_order' in df_cleaned.columns:
            unique_textboxes_count = len(df_cleaned.groupby(['file_name', 'text_box_order']))
        else:
            unique_textboxes_count = len(df_cleaned)
        
        return {
            'file_name': os.path.basename(file_path),
            'total_data_rows': len(df),
            'unique_textboxes': unique_textboxes_count,
            'different_rows': len(different_rows),
            'translation_rows': len(translation_rows_filtered) if 'translation_rows_filtered' in locals() else len(translation_rows),
            'typography_rows': len(typography_rows_original)
        }
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ ({os.path.basename(file_path)}): {str(e)}")
        return None

def batch_process_xlsx_files(input_directory):
    """
    ì…ë ¥ ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  XLSX íŒŒì¼ì„ ë°°ì¹˜ ì²˜ë¦¬
    
    Args:
        input_directory (str): ì…ë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    try:
        # ì…ë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
        if not os.path.exists(input_directory):
            print(f"âŒ ì˜¤ë¥˜: ì…ë ¥ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_directory}")
            return
        
        # XLSX íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (Excel ì„ì‹œ íŒŒì¼ ì œì™¸)
        all_xlsx_files = glob.glob(os.path.join(input_directory, "*.xlsx"))
        
        # Excel ì„ì‹œ íŒŒì¼ í•„í„°ë§ (~$ë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ë“¤ ì œì™¸)
        xlsx_files = [f for f in all_xlsx_files if not os.path.basename(f).startswith('~$')]
        
        if not xlsx_files:
            print(f"âŒ ì˜¤ë¥˜: {input_directory}ì—ì„œ XLSX íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # í•„í„°ë§ëœ ì„ì‹œ íŒŒì¼ì´ ìˆìœ¼ë©´ ì•Œë¦¼
        filtered_count = len(all_xlsx_files) - len(xlsx_files)
        if filtered_count > 0:
            print(f"ğŸ“‹ Excel ì„ì‹œ íŒŒì¼ {filtered_count}ê°œ ì œì™¸ë¨")
        
        print("=" * 80)
        print("ğŸ“Š ë°°ì¹˜ XLSX íŒŒì¼ ë¹„êµ ë„êµ¬")
        print("=" * 80)
        print(f"ğŸ“‚ ì…ë ¥ ë””ë ‰í† ë¦¬: {input_directory}")
        print(f"ğŸ“‹ ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(xlsx_files)}")
        print()
        
        results = []
        
        for xlsx_file in xlsx_files:
            # íŒŒì¼ëª…ì—ì„œ "ep_" ë’¤ì˜ ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ (í™•ì¥ì ì œì™¸)
            filename = os.path.basename(xlsx_file)
            if filename.startswith("ep_") and filename.endswith(".xlsx"):
                # ep_1.xlsx -> 1
                episode_num = filename[3:-5]  # "ep_"ë¥¼ ì œê±°í•˜ê³  ".xlsx"ë„ ì œê±°
                
                # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
                output_dir = os.path.join(input_directory, episode_num)
                Path(output_dir).mkdir(parents=True, exist_ok=True)
                
                # íŒŒì¼ ì²˜ë¦¬
                result = process_single_file(xlsx_file, output_dir)
                if result:
                    results.append(result)
            else:
                print(f"âš ï¸  ê±´ë„ˆë›°ê¸°: {filename} (ep_*.xlsx í˜•ì‹ì´ ì•„ë‹˜)")
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        if results:
            print("\n" + "=" * 80)
            print("ğŸ“Š ì „ì²´ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
            print("=" * 80)
            
            total_files = len(results)
            total_unique_textboxes = sum(r['unique_textboxes'] for r in results)
            total_data_rows = sum(r['total_data_rows'] for r in results)
            total_translation_rows = sum(r['translation_rows'] for r in results)
            total_typography_rows = sum(r['typography_rows'] for r in results)
            
            overall_modification_ratio = (total_translation_rows / total_unique_textboxes * 100) if total_unique_textboxes > 0 else 0
            
            print(f"âœ… ì²˜ë¦¬ ì™„ë£Œëœ íŒŒì¼ ìˆ˜: {total_files}")
            print(f"ğŸ“Š ì „ì²´ ê³ ìœ  í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜: {total_unique_textboxes:,}ê°œ")
            print(f"ğŸ“‹ ì „ì²´ ë°ì´í„° í–‰ ìˆ˜: {total_data_rows:,}ê°œ (ì¤‘ë³µ í¬í•¨)")
            print(f"ğŸ“ ì „ì²´ ë²ˆì—­ê²€ìˆ˜ í–‰ ìˆ˜: {total_translation_rows}")
            print(f"ğŸ¨ ì „ì²´ ì‹ìë²ˆì—­ê²€ìˆ˜ í–‰ ìˆ˜: {total_typography_rows}")
            print(f"ğŸ“ˆ ì „ì²´ ìˆ˜ì • ë¹„ìœ¨: {overall_modification_ratio:.2f}%")
            print()
            
            print("íŒŒì¼ë³„ ìƒì„¸ ê²°ê³¼:")
            for result in results:
                file_modification_ratio = (result['translation_rows'] / result['unique_textboxes'] * 100) if result['unique_textboxes'] > 0 else 0
                print(f"  ğŸ“„ {result['file_name']}: "
                      f"í…ìŠ¤íŠ¸ë°•ìŠ¤ {result['unique_textboxes']}ê°œ, "
                      f"ë²ˆì—­ê²€ìˆ˜ {result['translation_rows']}í–‰ ({file_modification_ratio:.1f}%), "
                      f"ì‹ìê²€ìˆ˜ {result['typography_rows']}í–‰")
        
    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def find_preprocessed_directory(project_uuid, episode_number):
    """project_uuidì™€ episode_numberë¥¼ ê¸°ë°˜ìœ¼ë¡œ preprocessed ë””ë ‰í† ë¦¬ ê²½ë¡œ ì°¾ê¸°"""
    # ê¸°ë³¸ data ë””ë ‰í† ë¦¬ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
    base_data_dir = "../data"
    project_dir = os.path.join(base_data_dir, project_uuid)
    
    if not os.path.exists(project_dir):
        print(f"âŒ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_dir}")
        return None
    
    # episode_number ë””ë ‰í† ë¦¬ ì°¾ê¸°
    episode_dir = os.path.join(project_dir, episode_number)
    if not os.path.exists(episode_dir):
        print(f"âŒ ì—í”¼ì†Œë“œ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {episode_dir}")
        return None
    
    # preprocessed ë””ë ‰í† ë¦¬ ì°¾ê¸°
    preprocessed_dir = os.path.join(episode_dir, "preprocessed")
    if not os.path.exists(preprocessed_dir):
        print(f"âŒ preprocessed ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {preprocessed_dir}")
        return None
    
    return preprocessed_dir

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ëª…ë ¹í–‰ ì¸ì í™•ì¸
    if len(sys.argv) != 3:
        print("âŒ ì‚¬ìš©ë²•: python3 3_xlsx_comparison.py <project_uuid> <episode_number>")
        return
    
    project_uuid = sys.argv[1]
    episode_number = sys.argv[2]
    
    print(f"ğŸ” í”„ë¡œì íŠ¸ UUID: {project_uuid}")
    print(f"ğŸ” ì—í”¼ì†Œë“œ ë²ˆí˜¸: {episode_number}")
    
    # preprocessed ë””ë ‰í† ë¦¬ ìë™ ê²€ìƒ‰
    input_directory = find_preprocessed_directory(project_uuid, episode_number)
    if not input_directory:
        return
    
    print(f"ğŸ“ ì…ë ¥ ë””ë ‰í† ë¦¬: {input_directory}")
    
    batch_process_xlsx_files(input_directory)

if __name__ == "__main__":
    main()
