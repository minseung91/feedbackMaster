#!/usr/bin/env python3
"""
preprocessed ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  translation_review_llm.csv íŒŒì¼ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ
í†µí•©ëœ statistics_summary.txtë¥¼ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import pandas as pd
import os
from pathlib import Path
from datetime import datetime
from collections import defaultdict

# íƒœê·¸ í‘œì‹œ ìˆœì„œ ì •ì˜
TAG_ORDER = [
    "ìœ¤ë¬¸",
    "ë¬¸ë²•", 
    "ì˜¤ì—­",
    "ì˜¤íƒˆì",
    "[ê°€ì´ë“œ ì¤€ìˆ˜] í‘œê¸°ë²• ì¤€ìˆ˜",
    "[ê°€ì´ë“œ ì¤€ìˆ˜] ì„¤ì •ì§‘ ë°˜ì˜",
    "[ê°€ì´ë“œ ì¤€ìˆ˜] ì´ì™¸ í•­ëª© ë¯¸ì¤€ìˆ˜"
]

# í‰ê°€ ê¸°ì¤€ ì •ì˜
EVALUATION_CRITERIA = {
    "ì˜¤ì—­": {
        "name_en": "Accuracy of Content",
        "weighted": True,
        "good_score": 6,
        "fair_score": 4,
        "poor_score": 0,
        "tags": ["ì˜¤ì—­"],
        "good_range": (0, 10),    # 0~10%
        "fair_range": (10, 30),   # 10~30%
        "poor_range": (30, 100)   # 30%~
    },
    "ë¬¸ë²•": {
        "name_en": "Grammar",
        "weighted": True,
        "good_score": 6,
        "fair_score": 4,
        "poor_score": 0,
        "tags": ["ë¬¸ë²•"],
        "good_range": (0, 10),
        "fair_range": (10, 30),
        "poor_range": (30, 100)
    },
    "ìœ¤ë¬¸": {
        "name_en": "Polishing",
        "weighted": True,
        "good_score": 6,
        "fair_score": 4,
        "poor_score": 0,
        "tags": ["ìœ¤ë¬¸"],
        "good_range": (0, 10),
        "fair_range": (10, 30),
        "poor_range": (30, 100)
    },
    "ì˜¤íƒˆì": {
        "name_en": "Typos",
        "weighted": False,
        "good_score": 3,
        "fair_score": 2,
        "poor_score": 1,
        "tags": ["ì˜¤íƒˆì"],
        "good_range": (0, 10),
        "fair_range": (10, 30),
        "poor_range": (30, 100)
    },
    "ê°€ì´ë“œ ì¤€ìˆ˜": {
        "name_en": "Guideline Adherance",
        "weighted": False,
        "good_score": 3,
        "fair_score": 2,
        "poor_score": 1,
        "tags": ["[ê°€ì´ë“œ ì¤€ìˆ˜] ì„¤ì •ì§‘ ë°˜ì˜", "[ê°€ì´ë“œ ì¤€ìˆ˜] í‘œê¸°ë²• ì¤€ìˆ˜", "[ê°€ì´ë“œ ì¤€ìˆ˜] ì´ì™¸ í•­ëª© ë¯¸ì¤€ìˆ˜"],
        "good_range": (0, 10),
        "fair_range": (10, 30),
        "poor_range": (30, 100)
    }
}

# ë“±ê¸‰ ê¸°ì¤€ ì •ì˜
GRADE_CRITERIA = {
    "A": {"range": (21, 24), "status": "í•©ê²©"},
    "B": {"range": (17, 20), "status": "í•©ê²©"},
    "C": {"range": (11, 16), "status": "ë¶ˆí•©ê²©"},
    "D": {"range": (2, 10), "status": "ë¶ˆí•©ê²©"}
}

def find_llm_csv_files(base_path):
    """
    ì§€ì •ëœ ê²½ë¡œì—ì„œ ëª¨ë“  translation_review_llm.csv íŒŒì¼ì„ ì°¾ì•„ ë°˜í™˜
    
    Args:
        base_path (str): ê¸°ë³¸ ê²€ìƒ‰ ê²½ë¡œ
        
    Returns:
        list: translation_review_llm.csv íŒŒì¼ ê²½ë¡œë“¤
    """
    csv_files = []
    base_path = Path(base_path)
    
    # í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ translation_review_llm.csv íŒŒì¼ ì°¾ê¸°
    for csv_file in base_path.glob("**/translation_review_llm.csv"):
        if csv_file.is_file():
            csv_files.append(str(csv_file))
    
    return sorted(csv_files)

def calculate_total_textboxes_from_xlsx_unified(csv_file_path):
    """
    CSV íŒŒì¼ ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ë‹¹í•˜ëŠ” ì›ë³¸ XLSX íŒŒì¼ì—ì„œ ì „ì²´ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜ë¥¼ ê³„ì‚°
    
    Args:
        csv_file_path (str): translation_review_llm.csv íŒŒì¼ ê²½ë¡œ
        
    Returns:
        int: ì „ì²´ ê³ ìœ  í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜
    """
    try:
        # CSV íŒŒì¼ ê²½ë¡œì—ì„œ ì—í”¼ì†Œë“œ ë²ˆí˜¸ ì¶”ì¶œ
        # ì˜ˆ: .../preprocessed/1/translation_review_llm.csv -> ep_1.xlsx
        csv_path = Path(csv_file_path)
        episode_dir = csv_path.parent.name  # "1", "2", "3" ë“±
        
        # preprocessed ë””ë ‰í† ë¦¬ë¡œ ì´ë™
        preprocessed_dir = csv_path.parent.parent
        
        # ì›ë³¸ XLSX íŒŒì¼ ê²½ë¡œ êµ¬ì„±
        xlsx_file_path = preprocessed_dir / f"ep_{episode_dir}.xlsx"
        
        if not xlsx_file_path.exists():
            print(f"ê²½ê³ : ì›ë³¸ XLSX íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {xlsx_file_path}")
            return 0
        
        # XLSX íŒŒì¼ ì½ê¸°
        df = pd.read_excel(xlsx_file_path)
        
        # file_nameê³¼ text_box_order ì¹¼ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if 'file_name' in df.columns and 'text_box_order' in df.columns:
            # ê³ ìœ í•œ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜ ê³„ì‚°
            unique_textboxes = df.groupby(['file_name', 'text_box_order']).size()
            total_unique_textboxes = len(unique_textboxes)
        else:
            # ì¹¼ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ì „ì²´ í–‰ ìˆ˜ ì‚¬ìš©
            total_unique_textboxes = len(df)
        
        return total_unique_textboxes
        
    except Exception as e:
        print(f"ì˜¤ë¥˜: XLSX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜ ê³„ì‚° ì‹¤íŒ¨ ({csv_file_path}): {e}")
        return 0

def extract_tags_from_llm_csv(csv_file_path):
    """
    translation_review_llm.csv íŒŒì¼ì—ì„œ íƒœê·¸ ì •ë³´ë¥¼ ì¶”ì¶œ
    
    Args:
        csv_file_path (str): CSV íŒŒì¼ ê²½ë¡œ
        
    Returns:
        dict: íŒŒì¼ë³„ íƒœê·¸ í†µê³„ ì •ë³´
    """
    try:
        # CSV íŒŒì¼ ì½ê¸°
        df = pd.read_csv(csv_file_path)
        
        if 'tag' not in df.columns:
            print(f"ê²½ê³ : '{csv_file_path}'ì—ì„œ 'tag' ì¹¼ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {
                'file_path': csv_file_path,
                'episode': Path(csv_file_path).parent.name,
                'tag_counts': {},
                'total_reviewed_items': 0,
                'total_textboxes': 0
            }
        
        # íƒœê·¸ ì •ë³´ ì¶”ì¶œ ë° ì¹´ìš´íŠ¸
        tag_counts = defaultdict(int)
        total_reviewed_items = 0
        
        for _, row in df.iterrows():
            tag_value = row['tag']
            if pd.notna(tag_value) and str(tag_value).strip() != '':
                # ì—¬ëŸ¬ íƒœê·¸ê°€ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²½ìš° ì²˜ë¦¬
                tags = [tag.strip() for tag in str(tag_value).split(',')]
                for tag in tags:
                    if tag:  # ë¹ˆ íƒœê·¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
                        tag_counts[tag] += 1
                total_reviewed_items += 1
        
        # ì›ë³¸ XLSX íŒŒì¼ì—ì„œ ì „ì²´ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜ ê³„ì‚°
        total_textboxes = calculate_total_textboxes_from_xlsx_unified(csv_file_path)
        
        return {
            'file_path': csv_file_path,
            'episode': Path(csv_file_path).parent.name,
            'tag_counts': dict(tag_counts),
            'total_reviewed_items': total_reviewed_items,
            'total_textboxes': total_textboxes
        }
        
    except Exception as e:
        print(f"ì˜¤ë¥˜: CSV íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({csv_file_path}): {e}")
        return {
            'file_path': csv_file_path,
            'episode': Path(csv_file_path).parent.name,
            'tag_counts': {},
            'total_reviewed_items': 0,
            'total_textboxes': 0
        }

def calculate_category_score(category_name, tag_counts, total_textboxes):
    """
    íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ì ìˆ˜ë¥¼ ê³„ì‚°
    
    Args:
        category_name (str): í‰ê°€ ì¹´í…Œê³ ë¦¬ëª… ("ì˜¤ì—­", "ë¬¸ë²•", "ìœ¤ë¬¸", "ì˜¤íƒˆì", "ê°€ì´ë“œ ì¤€ìˆ˜")
        tag_counts (dict): íƒœê·¸ë³„ ë°œìƒ íšŸìˆ˜
        total_textboxes (int): ì „ì²´ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜
        
    Returns:
        dict: ì¹´í…Œê³ ë¦¬ í‰ê°€ ê²°ê³¼
    """
    if category_name not in EVALUATION_CRITERIA:
        return None
    
    criteria = EVALUATION_CRITERIA[category_name]
    
    # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ íƒœê·¸ë“¤ì˜ ì´ ë°œìƒ íšŸìˆ˜ ê³„ì‚°
    total_count = 0
    for tag in criteria["tags"]:
        total_count += tag_counts.get(tag, 0)
    
    # í¼ì„¼íŠ¸ ê³„ì‚°
    percentage = (total_count / total_textboxes * 100) if total_textboxes > 0 else 0
    
    # ì ìˆ˜ ê²°ì •
    if criteria["good_range"][0] <= percentage < criteria["good_range"][1]:
        score = criteria["good_score"]
        grade = "GOOD"
    elif criteria["fair_range"][0] <= percentage < criteria["fair_range"][1]:
        score = criteria["fair_score"]
        grade = "FAIR"
    else:  # poor_range
        score = criteria["poor_score"]
        grade = "POOR"
    
    return {
        "category": category_name,
        "category_en": criteria["name_en"],
        "weighted": criteria["weighted"],
        "total_count": total_count,
        "percentage": percentage,
        "score": score,
        "grade": grade,
        "tags": criteria["tags"]
    }

def calculate_total_score_and_grade(category_scores):
    """
    ì „ì²´ ì ìˆ˜ ë° ë“±ê¸‰ ê³„ì‚°
    
    Args:
        category_scores (list): ê° ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        dict: ì „ì²´ ì ìˆ˜ ë° ë“±ê¸‰ ì •ë³´
    """
    total_score = sum(score["score"] for score in category_scores)
    
    # ë“±ê¸‰ ê²°ì •
    grade = "D"  # ê¸°ë³¸ê°’
    status = "ë¶ˆí•©ê²©"
    
    for grade_name, grade_info in GRADE_CRITERIA.items():
        min_score, max_score = grade_info["range"]
        if min_score <= total_score <= max_score:
            grade = grade_name
            status = grade_info["status"]
            break
    
    return {
        "total_score": total_score,
        "max_possible_score": 24,  # 6+6+6+3+3
        "grade": grade,
        "status": status
    }

def generate_scoring_report(unified_tag_counts, total_textboxes):
    """
    ì ìˆ˜ í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        unified_tag_counts (dict): í†µí•© íƒœê·¸ ë°œìƒ íšŸìˆ˜
        total_textboxes (int): ì „ì²´ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜
        
    Returns:
        str: ì ìˆ˜ í‰ê°€ ë¦¬í¬íŠ¸ í…ìŠ¤íŠ¸
    """
    category_scores = []
    
    # ê° ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°
    for category_name in EVALUATION_CRITERIA.keys():
        score_info = calculate_category_score(category_name, unified_tag_counts, total_textboxes)
        if score_info:
            category_scores.append(score_info)
    
    # ì „ì²´ ì ìˆ˜ ë° ë“±ê¸‰ ê³„ì‚°
    total_info = calculate_total_score_and_grade(category_scores)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    report = f"""
ğŸ“Š ë²ˆì—­ í’ˆì§ˆ í‰ê°€ ì ìˆ˜
{'='*80}

ğŸ† ì „ì²´ ê²°ê³¼:
- ì´ì : {total_info['total_score']}/{total_info['max_possible_score']}ì 
- ë“±ê¸‰: {total_info['grade']} ({total_info['status']})

ğŸ“‹ ì˜ì—­ë³„ ìƒì„¸ ì ìˆ˜:
"""
    
    for score_info in category_scores:
        weighted_mark = " (ê°€ì¤‘ì¹˜)" if score_info["weighted"] else ""
        report += f"""
â–¶ {score_info['category']} ({score_info['category_en']}){weighted_mark}
  - ë°œìƒ íšŸìˆ˜: {score_info['total_count']}íšŒ
  - ë°œìƒ ë¹„ìœ¨: {score_info['percentage']:.1f}%
  - í‰ê°€: {score_info['grade']}
  - ì ìˆ˜: {score_info['score']}ì 
  - í¬í•¨ íƒœê·¸: {', '.join(score_info['tags'])}"""
    
    report += f"""

ğŸ“ˆ ë“±ê¸‰ ê¸°ì¤€:
- Aë“±ê¸‰ (í•©ê²©): 21~24ì 
- Bë“±ê¸‰ (í•©ê²©): 17~20ì   
- Cë“±ê¸‰ (ë¶ˆí•©ê²©): 11~16ì 
- Dë“±ê¸‰ (ë¶ˆí•©ê²©): 2~10ì 

ğŸ’¡ í‰ê°€ ê¸°ì¤€:
- GOOD: 0~10% ë°œìƒ ì‹œ
- FAIR: 10~30% ë°œìƒ ì‹œ  
- POOR: 30% ì´ìƒ ë°œìƒ ì‹œ
"""
    
    return report

def generate_individual_statistics_report(stat, output_path):
    """
    ê°œë³„ ì—í”¼ì†Œë“œì˜ í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        stat (dict): ì—í”¼ì†Œë“œë³„ í†µê³„ ì •ë³´
        output_path (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    timestamp = datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')
    episode = stat['episode']
    textboxes = stat['total_textboxes']
    reviewed = stat['total_reviewed_items']
    review_ratio = (reviewed / textboxes * 100) if textboxes > 0 else 0
    
    report = f"""ë²ˆì—­ í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸ - ì—í”¼ì†Œë“œ {episode}
ìƒì„± ì‹œê°„: {timestamp}
{'='*50}

ğŸ“Š ì „ì²´ í†µê³„:
- ì „ì²´ ì‹¤ì§ˆ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜: {textboxes:,}ê°œ
- ê²€ìˆ˜ëœ í•­ëª© ìˆ˜: {reviewed}ê°œ
- ê²€ìˆ˜ ë¹„ìœ¨: {review_ratio:.2f}%

ğŸ·ï¸ íƒœê·¸ë³„ ë°œìƒ ë¹ˆë„ (ì „ì²´ í…ìŠ¤íŠ¸ë°•ìŠ¤ ê¸°ì¤€):
"""
    
    # ì •ì˜ëœ ìˆœì„œëŒ€ë¡œ íƒœê·¸ í‘œì‹œ (ì—†ëŠ” ê²½ìš° 0íšŒë¡œ í‘œì‹œ)
    for tag in TAG_ORDER:
        count = stat['tag_counts'].get(tag, 0)
        tag_percentage = (count / textboxes * 100) if textboxes > 0 else 0
        report += f"  - {tag}: {count}íšŒ ({tag_percentage:.1f}%)\n"
    
    # íŒŒì¼ì— ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… ì—í”¼ì†Œë“œ {episode} í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±: {output_path}")

def generate_unified_statistics_report(file_statistics, output_path):
    """
    ëª¨ë“  íŒŒì¼ì˜ í†µê³„ë¥¼ í†µí•©í•˜ì—¬ ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„± (ì „ì²´ í†µê³„ ë¶€ë¶„ë§Œ)
    
    Args:
        file_statistics (list): ê° íŒŒì¼ë³„ í†µê³„ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        output_path (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    if not file_statistics:
        print("ìƒì„±í•  í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì „ì²´ í†µê³„ ê³„ì‚°
    total_files = len(file_statistics)
    total_textboxes = sum(stat['total_textboxes'] for stat in file_statistics)
    total_reviewed_items = sum(stat['total_reviewed_items'] for stat in file_statistics)
    
    # ì „ì²´ íƒœê·¸ í†µê³„ í†µí•©
    unified_tag_counts = defaultdict(int)
    for stat in file_statistics:
        for tag, count in stat['tag_counts'].items():
            unified_tag_counts[tag] += count
    
    # ë¦¬í¬íŠ¸ ìƒì„± (ì „ì²´ í†µê³„ ë¶€ë¶„ë§Œ)
    timestamp = datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')
    
    report = f"""í†µí•© ë²ˆì—­ í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸
ìƒì„± ì‹œê°„: {timestamp}
{'='*80}

ğŸ“Š ì „ì²´ í†µê³„:
- ë¶„ì„ëœ ì—í”¼ì†Œë“œ ìˆ˜: {total_files}ê°œ
- ì „ì²´ ì‹¤ì§ˆ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìˆ˜: {total_textboxes:,}ê°œ
- ê²€ìˆ˜ëœ í•­ëª© ìˆ˜: {total_reviewed_items}ê°œ
- ê²€ìˆ˜ ë¹„ìœ¨: {(total_reviewed_items / total_textboxes * 100) if total_textboxes > 0 else 0:.2f}%

ğŸ·ï¸ íƒœê·¸ë³„ ë°œìƒ ë¹ˆë„ (ì „ì²´ í…ìŠ¤íŠ¸ë°•ìŠ¤ ê¸°ì¤€):
"""
    
    # ì •ì˜ëœ ìˆœì„œëŒ€ë¡œ íƒœê·¸ í‘œì‹œ (ì—†ëŠ” ê²½ìš° 0íšŒë¡œ í‘œì‹œ)
    for tag in TAG_ORDER:
        count = unified_tag_counts.get(tag, 0)
        percentage = (count / total_textboxes) * 100 if total_textboxes > 0 else 0
        report += f"  - {tag}: {count}íšŒ ({percentage:.1f}%)\n"
    
    # ì ìˆ˜ í‰ê°€ ë¦¬í¬íŠ¸ ì¶”ê°€
    scoring_report = generate_scoring_report(unified_tag_counts, total_textboxes)
    report += scoring_report
    
    # íŒŒì¼ì— ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… í†µí•© í†µê³„ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
    print(f"   - ë¶„ì„ëœ ì—í”¼ì†Œë“œ: {total_files}ê°œ")
    print(f"   - ì „ì²´ í…ìŠ¤íŠ¸ë°•ìŠ¤: {total_textboxes:,}ê°œ")
    print(f"   - ê²€ìˆ˜ëœ í•­ëª©: {total_reviewed_items}ê°œ")

def process_unified_statistics(base_path):
    """
    ì§€ì •ëœ ê²½ë¡œì˜ ëª¨ë“  translation_review_llm.csv íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í†µí•© í†µê³„ ìƒì„±
    
    Args:
        base_path (str): ê¸°ë³¸ ê²€ìƒ‰ ê²½ë¡œ
    """
    print(f"\n{'='*80}")
    print(f"í†µí•© í†µê³„ ìƒì„± ì‹œì‘")
    print(f"ê¸°ë³¸ ê²½ë¡œ: {base_path}")
    print(f"{'='*80}")
    
    # ëª¨ë“  translation_review_llm.csv íŒŒì¼ ì°¾ê¸°
    llm_csv_files = find_llm_csv_files(base_path)
    
    if not llm_csv_files:
        print(f"'{base_path}' ê²½ë¡œì—ì„œ translation_review_llm.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ë°œê²¬ëœ íŒŒì¼ ëª©ë¡:")
    for i, csv_file in enumerate(llm_csv_files, 1):
        episode_name = Path(csv_file).parent.name
        print(f"  {i}. ì—í”¼ì†Œë“œ {episode_name}: {csv_file}")
    
    # ê° íŒŒì¼ì—ì„œ í†µê³„ ì¶”ì¶œ ë° ê°œë³„ ë¦¬í¬íŠ¸ ìƒì„±
    file_statistics = []
    
    print(f"\nğŸ“Š íŒŒì¼ë³„ í†µê³„ ì¶”ì¶œ ë° ê°œë³„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    for csv_file in llm_csv_files:
        csv_path = Path(csv_file)
        episode_name = csv_path.parent.name
        print(f"ì²˜ë¦¬ ì¤‘: ì—í”¼ì†Œë“œ {episode_name}")
        
        # í†µê³„ ì¶”ì¶œ
        stat = extract_tags_from_llm_csv(csv_file)
        file_statistics.append(stat)
        
        # ê°œë³„ ì—í”¼ì†Œë“œ statistics_summary.txt ìƒì„±
        individual_output_path = csv_path.parent / "statistics_summary.txt"
        generate_individual_statistics_report(stat, individual_output_path)
    
    # í†µí•© ë¦¬í¬íŠ¸ ìƒì„± (ì „ì²´ í†µê³„ ë¶€ë¶„ë§Œ)
    output_path = Path(base_path) / "unified_statistics_summary.txt"
    generate_unified_statistics_report(file_statistics, output_path)

def find_preprocessed_directory(project_uuid, episode_number):
    """project_uuidì™€ episode_numberë¥¼ ê¸°ë°˜ìœ¼ë¡œ preprocessed ë””ë ‰í† ë¦¬ ê²½ë¡œ ì°¾ê¸°"""
    # ê¸°ë³¸ data ë””ë ‰í† ë¦¬ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
    base_data_dir = "../data"
    project_dir = os.path.join(base_data_dir, project_uuid)
    
    if not os.path.exists(project_dir):
        print(f"âŒ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_dir}")
        return None
    
    # episode_number ë””ë ‰í† ë¦¬ ì°¾ê¸°
    episode_dir = os.path.join(project_dir, episode_number)
    if not os.path.exists(episode_dir):
        print(f"âŒ ì—í”¼ì†Œë“œ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {episode_dir}")
        return None
    
    # preprocessed ë””ë ‰í† ë¦¬ ì°¾ê¸°
    preprocessed_dir = os.path.join(episode_dir, "preprocessed")
    if not os.path.exists(preprocessed_dir):
        print(f"âŒ preprocessed ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {preprocessed_dir}")
        return None
    
    return preprocessed_dir

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys
    
    # ëª…ë ¹í–‰ ì¸ì í™•ì¸
    if len(sys.argv) != 3:
        print("âŒ ì‚¬ìš©ë²•: python3 5_generate_unified_statistics.py <project_uuid> <episode_number>")
        return
    
    project_uuid = sys.argv[1]
    episode_number = sys.argv[2]
    
    print(f"ğŸ” í”„ë¡œì íŠ¸ UUID: {project_uuid}")
    print(f"ğŸ” ì—í”¼ì†Œë“œ ë²ˆí˜¸: {episode_number}")
    
    # preprocessed ë””ë ‰í† ë¦¬ ìë™ ê²€ìƒ‰
    base_path = find_preprocessed_directory(project_uuid, episode_number)
    if not base_path:
        return
    
    print(f"ğŸ“ ê¸°ë³¸ ê²½ë¡œ: {base_path}")
    
    # í†µí•© í†µê³„ ì²˜ë¦¬ ì‹¤í–‰
    process_unified_statistics(base_path)

if __name__ == "__main__":
    main()
