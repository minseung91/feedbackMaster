#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
4_comment_generator.py ê²°ê³¼ë¥¼ Google Sheetsì— ì—…ë¡œë“œí•˜ëŠ” ëª¨ë“ˆ
translation_review_llm.csv íŒŒì¼ë“¤ì„ ìˆ˜ì§‘í•˜ì—¬ "ë²ˆì—­ ì‹ì‚¬ ê²€ìˆ˜ ì½”ë©˜íŠ¸ ìƒì„± ì‹œíŠ¸"ì— ì—…ë¡œë“œ
"""

import pandas as pd
import os
import sys
from pathlib import Path
import re
from datetime import datetime
import logging
import gspread
from google.oauth2.service_account import Credentials

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class TranslationReviewSheetsUploader:
    """ë²ˆì—­ ê²€ìˆ˜ ê²°ê³¼ë¥¼ Google Sheetsì— ì—…ë¡œë“œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, credentials_path: str, spreadsheet_id: str):
        """
        ì´ˆê¸°í™”
        
        Args:
            credentials_path (str): Google API credentials.json íŒŒì¼ ê²½ë¡œ
            spreadsheet_id (str): ëŒ€ìƒ Google Spreadsheet ID
        """
        self.credentials_path = credentials_path
        self.spreadsheet_id = spreadsheet_id
        self.client = self._authenticate()
    
    def _authenticate(self):
        """Google Sheets API ì¸ì¦"""
        try:
            scopes = [
                'https://www.googleapis.com/auth/spreadsheets',
                'https://www.googleapis.com/auth/drive'
            ]
            credentials = Credentials.from_service_account_file(
                self.credentials_path, 
                scopes=scopes
            )
            return gspread.authorize(credentials)
        except Exception as e:
            logger.error(f"Google Sheets API ì¸ì¦ ì‹¤íŒ¨: {e}")
            raise
        
    def extract_project_uuid(self, file_path: str) -> str:
        """
        íŒŒì¼ ê²½ë¡œì—ì„œ project_uuid ì¶”ì¶œ
        
        Args:
            file_path (str): translation_review_llm.csv íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: project_uuid (ì˜ˆ: "60af877a-4d7e-465a-875d-37c6f324917e")
        """
        try:
            # UUID íŒ¨í„´ ë§¤ì¹­ (8-4-4-4-12 í˜•ì‹)
            uuid_pattern = r'([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})'
            match = re.search(uuid_pattern, file_path, re.IGNORECASE)
            
            if match:
                return match.group(1)
            else:
                logger.warning(f"UUIDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                return "unknown"
                
        except Exception as e:
            logger.error(f"UUID ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "unknown"
    
    def extract_episode_number(self, file_path: str) -> str:
        """
        íŒŒì¼ ê²½ë¡œì—ì„œ ì—í”¼ì†Œë“œ ë²ˆí˜¸ ì¶”ì¶œ
        
        Args:
            file_path (str): translation_review_llm.csv íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: ì—í”¼ì†Œë“œ ë²ˆí˜¸ (ì˜ˆ: "1", "2", "3")
        """
        try:
            path = Path(file_path)
            # íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ì´ë¦„ì´ ì—í”¼ì†Œë“œ ë²ˆí˜¸ (ì˜ˆ: "1", "2", "3")
            episode_dir = path.parent.name
            
            # ìˆ«ìì¸ì§€ í™•ì¸
            if episode_dir.isdigit():
                return episode_dir
            else:
                logger.warning(f"ì—í”¼ì†Œë“œ ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                return "unknown"
                
        except Exception as e:
            logger.error(f"ì—í”¼ì†Œë“œ ë²ˆí˜¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "unknown"
    
    def get_project_name_from_xlsx(self, file_path: str) -> str:
        """
        í•´ë‹¹í•˜ëŠ” ep_X.xlsx íŒŒì¼ì—ì„œ job_name ê°’ì„ ì¶”ì¶œ
        
        Args:
            file_path (str): translation_review_llm.csv íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: project_name (job_name ê°’)
        """
        try:
            path = Path(file_path)
            episode_num = path.parent.name  # "1", "2", "3" ë“±
            
            # preprocessed ë””ë ‰í† ë¦¬ë¡œ ì´ë™
            preprocessed_dir = path.parent.parent
            
            # í•´ë‹¹ ì—í”¼ì†Œë“œì˜ XLSX íŒŒì¼ ê²½ë¡œ
            xlsx_file_path = preprocessed_dir / f"ep_{episode_num}.xlsx"
            
            if not xlsx_file_path.exists():
                logger.warning(f"XLSX íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {xlsx_file_path}")
                return "unknown"
            
            # XLSX íŒŒì¼ ì½ê¸°
            df = pd.read_excel(xlsx_file_path)
            
            # job_name ì¹¼ëŸ¼ì—ì„œ ì²« ë²ˆì§¸ ê°’ ê°€ì ¸ì˜¤ê¸°
            if 'job_name' in df.columns:
                job_names = df['job_name'].dropna().unique()
                if len(job_names) > 0:
                    project_name = str(job_names[0])
                    logger.info(f"í”„ë¡œì íŠ¸ëª… ì¶”ì¶œ: {project_name} (from {xlsx_file_path.name})")
                    return project_name
                else:
                    logger.warning(f"job_name ê°’ì´ ì—†ìŠµë‹ˆë‹¤: {xlsx_file_path}")
                    return "unknown"
            else:
                logger.warning(f"job_name ì¹¼ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {xlsx_file_path}")
                return "unknown"
                
        except Exception as e:
            logger.error(f"í”„ë¡œì íŠ¸ëª… ì¶”ì¶œ ì‹¤íŒ¨ ({file_path}): {e}")
            return "unknown"
    
    def find_all_translation_review_llm_files(self, base_path: str) -> list:
        """
        ì§€ì •ëœ ê²½ë¡œì—ì„œ ëª¨ë“  translation_review_llm.csv íŒŒì¼ì„ ì°¾ì•„ ë°˜í™˜
        
        Args:
            base_path (str): ê²€ìƒ‰í•  ê¸°ë³¸ ê²½ë¡œ
            
        Returns:
            list: translation_review_llm.csv íŒŒì¼ ê²½ë¡œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        csv_files = []
        base_path = Path(base_path)
        
        # glob íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ translation_review_llm.csv íŒŒì¼ ì°¾ê¸°
        for csv_file in base_path.glob("**/translation_review_llm.csv"):
            if csv_file.is_file():
                csv_files.append(str(csv_file))
        
        # ì—í”¼ì†Œë“œ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ê²½ë¡œì—ì„œ ì—í”¼ì†Œë“œ ë²ˆí˜¸ ì¶”ì¶œí•˜ì—¬ ì •ë ¬)
        def get_sort_key(file_path):
            try:
                path = Path(file_path)
                episode_num = int(path.parent.name)
                return episode_num
            except:
                return 999  # ì—í”¼ì†Œë“œ ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ë§ˆì§€ë§‰ìœ¼ë¡œ
        
        csv_files.sort(key=get_sort_key)
        
        logger.info(f"ë°œê²¬ëœ translation_review_llm.csv íŒŒì¼: {len(csv_files)}ê°œ")
        for file in csv_files:
            logger.info(f"  - {file}")
        
        return csv_files
    
    def process_single_csv_file(self, csv_file_path: str) -> list:
        """
        ë‹¨ì¼ translation_review_llm.csv íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ Google Sheets ì—…ë¡œë“œìš© ë°ì´í„°ë¡œ ë³€í™˜
        
        Args:
            csv_file_path (str): ì²˜ë¦¬í•  CSV íŒŒì¼ ê²½ë¡œ
            
        Returns:
            list: ì—…ë¡œë“œìš© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        try:
            # CSV íŒŒì¼ ì½ê¸°
            df = pd.read_csv(csv_file_path)
            
            # í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
            project_uuid = self.extract_project_uuid(csv_file_path)
            project_name = self.get_project_name_from_xlsx(csv_file_path)
            ep_num = self.extract_episode_number(csv_file_path)
            
            logger.info(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘: {Path(csv_file_path).name}")
            logger.info(f"  - Project UUID: {project_uuid}")
            logger.info(f"  - Project Name: {project_name}")
            logger.info(f"  - Episode: {ep_num}")
            logger.info(f"  - ë°ì´í„° í–‰ ìˆ˜: {len(df)}")
            
            # Google Sheets ì—…ë¡œë“œìš© ë°ì´í„° ë³€í™˜
            upload_data = []
            
            for _, row in df.iterrows():
                upload_row = {
                    'project_uuid': project_uuid,
                    'project_name': project_name,
                    'ep_num': ep_num,
                    'file_name': row.get('file_name', ''),
                    'text_box_order': row.get('text_box_order', ''),
                    'target': row.get('target', ''),
                    'val': row.get('val', ''),
                    'tag': row.get('tag', ''),
                    'comment': row.get('comment', '')
                }
                upload_data.append(upload_row)
            
            return upload_data
            
        except Exception as e:
            logger.error(f"CSV íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({csv_file_path}): {e}")
            return []
    
    def upload_all_files_to_sheets(self, base_path: str, sheet_name: str = "ë²ˆì—­ ì‹ì‚¬ ê²€ìˆ˜ ì½”ë©˜íŠ¸ ìƒì„± ì‹œíŠ¸") -> bool:
        """
        ëª¨ë“  translation_review_llm.csv íŒŒì¼ì„ Google Sheetsì— ì—…ë¡œë“œ
        
        Args:
            base_path (str): ê²€ìƒ‰í•  ê¸°ë³¸ ê²½ë¡œ
            sheet_name (str): ì—…ë¡œë“œí•  ì‹œíŠ¸ ì´ë¦„
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ëª¨ë“  translation_review_llm.csv íŒŒì¼ ì°¾ê¸°
            csv_files = self.find_all_translation_review_llm_files(base_path)
            
            if not csv_files:
                logger.warning(f"'{base_path}' ê²½ë¡œì—ì„œ translation_review_llm.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
            all_upload_data = []
            
            for csv_file in csv_files:
                file_data = self.process_single_csv_file(csv_file)
                all_upload_data.extend(file_data)
            
            if not all_upload_data:
                logger.warning("ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            logger.info(f"ì´ {len(all_upload_data)}ê°œì˜ ë°ì´í„° í–‰ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
            
            # Google Sheetsì— ì—…ë¡œë“œ
            return self.upload_data_to_sheets(all_upload_data, sheet_name)
            
        except Exception as e:
            logger.error(f"ì „ì²´ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def upload_data_to_sheets(self, upload_data: list, sheet_name: str) -> bool:
        """
        ë°ì´í„°ë¥¼ Google Sheetsì— ì—…ë¡œë“œ
        
        Args:
            upload_data (list): ì—…ë¡œë“œí•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            sheet_name (str): ì‹œíŠ¸ ì´ë¦„
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
            spreadsheet = self.client.open_by_key(self.spreadsheet_id)
            
            # ì‹œíŠ¸ ì°¾ê¸° ë˜ëŠ” ìƒì„±
            try:
                worksheet = spreadsheet.worksheet(sheet_name)
                logger.info(f"ê¸°ì¡´ ì‹œíŠ¸ ì‚¬ìš©: {sheet_name}")
            except:
                # ìƒˆ ì‹œíŠ¸ ìƒì„± (ì¶©ë¶„í•œ í–‰ê³¼ ì—´ í™•ë³´)
                worksheet = spreadsheet.add_worksheet(
                    title=sheet_name, 
                    rows=len(upload_data) + 100,  # ì—¬ìœ  í–‰
                    cols=10  # 9ê°œ ì¹¼ëŸ¼ + ì—¬ìœ 
                )
                logger.info(f"ìƒˆ ì‹œíŠ¸ ìƒì„±: {sheet_name}")
            
            # í—¤ë” ì„¤ì •
            headers = ['project_uuid', 'project_name', 'ep_num', 'file_name', 'text_box_order', 'target', 'val', 'tag', 'comment']
            
            # NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³ , ëª¨ë“  ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
            def safe_str(value):
                if pd.isna(value) or value is None:
                    return ''
                return str(value)
            
            # ê¸°ì¡´ ë°ì´í„° í™•ì¸
            existing_data = worksheet.get_all_values()
            
            if not existing_data:
                # ì‹œíŠ¸ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°: í—¤ë” + ìƒˆ ë°ì´í„° ì¶”ê°€
                print("ğŸ“‹ ë¹ˆ ì‹œíŠ¸ì— í—¤ë”ì™€ ë°ì´í„°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.")
                sheet_data = [headers]
                for row_data in upload_data:
                    sheet_row = [
                        safe_str(row_data.get('project_uuid', '')),
                        safe_str(row_data.get('project_name', '')),
                        safe_str(row_data.get('ep_num', '')),
                        safe_str(row_data.get('file_name', '')),
                        safe_str(row_data.get('text_box_order', '')),
                        safe_str(row_data.get('target', '')),
                        safe_str(row_data.get('val', '')),
                        safe_str(row_data.get('tag', '')),
                        safe_str(row_data.get('comment', ''))
                    ]
                    sheet_data.append(sheet_row)
                
                range_name = f"A1:{chr(ord('A') + len(headers) - 1)}{len(sheet_data)}"
                worksheet.update(sheet_data, range_name)
            else:
                # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°: ì¤‘ë³µ í™•ì¸ í›„ ì¶”ê°€
                print(f"ğŸ“‹ ê¸°ì¡´ ë°ì´í„° {len(existing_data)-1}ê°œ í–‰ ë°œê²¬. ì¤‘ë³µ í™•ì¸ ì¤‘...")
                
                # ê¸°ì¡´ ë°ì´í„°ì—ì„œ project_uuid + ep_num + file_name + text_box_order ì¡°í•© ì¶”ì¶œ
                existing_combinations = set()
                for row in existing_data[1:]:  # í—¤ë” ì œì™¸
                    if len(row) >= 5:
                        combination = f"{row[0]}_{row[2]}_{row[3]}_{row[4]}"  # project_uuid + ep_num + file_name + text_box_order
                        existing_combinations.add(combination)
                
                # ìƒˆë¡œ ì¶”ê°€í•  ë°ì´í„° í•„í„°ë§
                new_rows = []
                skipped_count = 0
                for row_data in upload_data:
                    project_uuid = safe_str(row_data.get('project_uuid', ''))
                    ep_num = safe_str(row_data.get('ep_num', ''))
                    file_name = safe_str(row_data.get('file_name', ''))
                    text_box_order = safe_str(row_data.get('text_box_order', ''))
                    combination = f"{project_uuid}_{ep_num}_{file_name}_{text_box_order}"
                    
                    if combination not in existing_combinations:
                        new_row = [
                            project_uuid,
                            safe_str(row_data.get('project_name', '')),
                            ep_num,
                            file_name,
                            text_box_order,
                            safe_str(row_data.get('target', '')),
                            safe_str(row_data.get('val', '')),
                            safe_str(row_data.get('tag', '')),
                            safe_str(row_data.get('comment', ''))
                        ]
                        new_rows.append(new_row)
                    else:
                        skipped_count += 1
                
                if new_rows:
                    # ê¸°ì¡´ ë°ì´í„° ë‹¤ìŒ í–‰ë¶€í„° ì¶”ê°€
                    start_row = len(existing_data) + 1
                    end_row = start_row + len(new_rows) - 1
                    range_name = f"A{start_row}:{chr(ord('A') + len(headers) - 1)}{end_row}"
                    worksheet.update(new_rows, range_name)
                    print(f"ğŸ“ {len(new_rows)}ê°œì˜ ìƒˆ ë°ì´í„°ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    if skipped_count > 0:
                        print(f"âš ï¸ {skipped_count}ê°œì˜ ì¤‘ë³µ ë°ì´í„°ê°€ ê±´ë„ˆë›°ì–´ì¡ŒìŠµë‹ˆë‹¤.")
                else:
                    print(f"ğŸ“‹ ì¶”ê°€í•  ìƒˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ({len(upload_data)}ê°œ ëª¨ë‘ ì¤‘ë³µ)")
            
            logger.info(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ!")
            logger.info(f"  - ì‹œíŠ¸: {sheet_name}")
            logger.info(f"  - ì—…ë¡œë“œëœ í–‰: {len(upload_data)}í–‰ (í—¤ë” ì œì™¸)")
            logger.info(f"  - ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URL: https://docs.google.com/spreadsheets/d/{self.spreadsheet_id}")
            
            return True
            
        except Exception as e:
            logger.error(f"Google Sheets ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False


def find_preprocessed_directory(project_uuid, episode_number):
    """project_uuidì™€ episode_numberë¥¼ ê¸°ë°˜ìœ¼ë¡œ preprocessed ë””ë ‰í† ë¦¬ ê²½ë¡œ ì°¾ê¸°"""
    # ê¸°ë³¸ data ë””ë ‰í† ë¦¬ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
    base_data_dir = "../data"
    project_dir = os.path.join(base_data_dir, project_uuid)
    
    if not os.path.exists(project_dir):
        print(f"âŒ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_dir}")
        return None
    
    # episode_number ë””ë ‰í† ë¦¬ ì°¾ê¸°
    episode_dir = os.path.join(project_dir, episode_number)
    if not os.path.exists(episode_dir):
        print(f"âŒ ì—í”¼ì†Œë“œ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {episode_dir}")
        return None
    
    # preprocessed ë””ë ‰í† ë¦¬ ì°¾ê¸°
    preprocessed_dir = os.path.join(episode_dir, "preprocessed")
    if not os.path.exists(preprocessed_dir):
        print(f"âŒ preprocessed ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {preprocessed_dir}")
        return None
    
    return preprocessed_dir

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ëª…ë ¹í–‰ ì¸ì í™•ì¸
    if len(sys.argv) != 3:
        print("âŒ ì‚¬ìš©ë²•: python3 5_sheets_uploader_for_llm_results.py <project_uuid> <episode_number>")
        return
    
    project_uuid = sys.argv[1]
    episode_number = sys.argv[2]
    
    print(f"ğŸ” í”„ë¡œì íŠ¸ UUID: {project_uuid}")
    print(f"ğŸ” ì—í”¼ì†Œë“œ ë²ˆí˜¸: {episode_number}")
    
    # preprocessed ë””ë ‰í† ë¦¬ ìë™ ê²€ìƒ‰
    base_path = find_preprocessed_directory(project_uuid, episode_number)
    if not base_path:
        return
    
    print(f"ğŸ“ ê¸°ë³¸ ê²½ë¡œ: {base_path}")
    
    # ì„¤ì • (ìƒëŒ€ê²½ë¡œ ì‚¬ìš©)
    CREDENTIALS_PATH = "credentials.json"  # í˜„ì¬ process ë””ë ‰í† ë¦¬ì— ìˆìŒ
    SPREADSHEET_ID = "1oYi9dxDl3HcPzld3mZlXFXAEK5V0HU22HZLthCqmMgo"  # ì‚¬ìš©ì ì œê³µ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID
    SHEET_NAME = "ë²ˆì—­ ì‹ì‚¬ ê²€ìˆ˜ ì½”ë©˜íŠ¸ ìƒì„± ì‹œíŠ¸"
    
    try:
        print("=== Translation Review LLM Results â†’ Google Sheets ì—…ë¡œë“œ ===")
        print(f"ğŸ“Š ëŒ€ìƒ ìŠ¤í”„ë ˆë“œì‹œíŠ¸: {SPREADSHEET_ID}")
        print(f"ğŸ“‹ ì‹œíŠ¸ ì´ë¦„: {SHEET_NAME}")
        print(f"ğŸ“ ê²€ìƒ‰ ê²½ë¡œ: {base_path}")
        print()
        
        # ì—…ë¡œë” ì´ˆê¸°í™”
        uploader = TranslationReviewSheetsUploader(CREDENTIALS_PATH, SPREADSHEET_ID)
        
        # í•´ë‹¹ ì—í”¼ì†Œë“œ ë²”ìœ„ì˜ translation_review_llm.csv íŒŒì¼ì„ Google Sheetsì— ì—…ë¡œë“œ
        success = uploader.upload_all_files_to_sheets(base_path, SHEET_NAME)
        
        if success:
            print("ğŸ‰ ëª¨ë“  íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ”— í™•ì¸: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}")
        else:
            print("âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.error(f"ë©”ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main()
