"""
Gemini API ë° Anthropic API í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚° ëª¨ë“ˆ
"""
import threading

class TokenCostCalculator:
    def __init__(self, model_name="gemini-2.5-flash"):
        # ëª¨ë¸ë³„ ê°€ê²© ì •ë³´ (100ë§Œ í† í°ë‹¹ ë‹¬ëŸ¬)
        self.pricing = {
            "gemini-2.5-flash": {
                "input": 0.3,
                "output": 2.5,
                "thinking": 2.5,
                "cached": 0.075  # Flash cached input tokens
            },
            "gemini-2.5-pro": {
                # 20ë§Œ í† í° ë¯¸ë§Œ
                "input_low": 1.25,
                "output_low": 10.0,
                "cached_low": 0.31,
                # 20ë§Œ í† í° ì´ìƒ
                "input_high": 2.5,
                "output_high": 15.0,
                "cached_high": 0.625,
                "thinking": 10.0,  # Pro thinking tokens
                "threshold": 200_000  # 20ë§Œ í† í° ì„ê³„ê°’
            },
            # Anthropic Claude ëª¨ë¸ë“¤
            "claude-3-5-sonnet-20241022": {
                "input": 3.0,  # $3.00 per 1M input tokens
                "output": 15.0  # $15.00 per 1M output tokens
            },
            "claude-3-5-haiku-20241022": {
                "input": 1.0,  # $1.00 per 1M input tokens
                "output": 5.0   # $5.00 per 1M output tokens
            },
            "claude-3-opus-20240229": {
                "input": 15.0,  # $15.00 per 1M input tokens
                "output": 75.0  # $75.00 per 1M output tokens
            },
            "claude-3-7-sonnet": {
                # 20ë§Œ í† í° ë¯¸ë§Œ
                "input_low": 3.0,    # $3.00 per 1M tokens
                "output_low": 15.0,  # $15.00 per 1M tokens
                "cache_write_low": 3.75,  # $3.75 per 1M tokens
                "cache_read_low": 0.30,   # $0.30 per 1M tokens
                # 20ë§Œ í† í° ì´ìƒ
                "input_high": 6.0,    # $6.00 per 1M tokens
                "output_high": 22.5,  # $22.50 per 1M tokens
                "cache_write_high": 7.50,  # $7.50 per 1M tokens
                "cache_read_high": 0.60,   # $0.60 per 1M tokens
                "threshold": 200_000  # 20ë§Œ í† í° ì„ê³„ê°’
            },
            # Claude Sonnet 4 ëª¨ë¸ë“¤ (Claude 3.7ê³¼ ë™ì¼í•œ ê°€ê²©)
            "claude-sonnet-4": {
                # 20ë§Œ í† í° ë¯¸ë§Œ
                "input_low": 3.0,    # $3.00 per 1M tokens
                "output_low": 15.0,  # $15.00 per 1M tokens
                "cache_write_low": 3.75,  # $3.75 per 1M tokens
                "cache_read_low": 0.30,   # $0.30 per 1M tokens
                # 20ë§Œ í† í° ì´ìƒ
                "input_high": 6.0,    # $6.00 per 1M tokens
                "output_high": 22.5,  # $22.50 per 1M tokens
                "cache_write_high": 7.50,  # $7.50 per 1M tokens
                "cache_read_high": 0.60,   # $0.60 per 1M tokens
                "threshold": 200_000  # 20ë§Œ í† í° ì„ê³„ê°’
            }
        }
        
        self.model_name = model_name
        
        # ëª¨ë¸ íƒ€ì… ê°ì§€ (Gemini vs Anthropic)
        self.is_anthropic = model_name.startswith('claude')
        
        # Claude 3.7ê³¼ Claude Sonnet 4ëŠ” ë³µì¡í•œ ê°€ê²© êµ¬ì¡°ë¥¼ ê°€ì§
        self.is_claude_3_7 = model_name == 'claude-3-7-sonnet'
        self.is_claude_sonnet_4 = 'claude-sonnet-4' in model_name
        self.has_complex_pricing = self.is_claude_3_7 or self.is_claude_sonnet_4
        
        # ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬ëŠ” ì†ì„± ì„¤ì • í›„ì— ìˆ˜í–‰
        self.validate_model()
        
        # ì „ì²´ ëˆ„ì  ë¹„ìš© ì¶”ì 
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.total_thinking_tokens = 0
        self.total_cached_tokens = 0
        self.total_cache_write_tokens = 0  # Claude 3.7ìš©
        self.total_cost = 0.0
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•œ ë½
        self._lock = threading.Lock()
    
    def validate_model(self):
        """ì§€ì›ë˜ëŠ” ëª¨ë¸ì¸ì§€ í™•ì¸"""
        # Claude Sonnet 4 ëª¨ë¸ë“¤ì€ ëª¨ë¸ëª…ì— 'claude-sonnet-4'ê°€ í¬í•¨ëœ ê²½ìš° ìœ íš¨
        if self.is_claude_sonnet_4:
            return  # Claude Sonnet 4 ëª¨ë¸ë“¤ì€ ëª¨ë‘ ì§€ì›
        
        if self.model_name not in self.pricing:
            supported_models = list(self.pricing.keys()) + ["claude-sonnet-4-* (ì„ì˜ì˜ Claude Sonnet 4 ëª¨ë¸)"]
            raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸: {self.model_name}. ì§€ì› ëª¨ë¸: {supported_models}")
    
    def get_model_pricing(self, input_tokens=0):
        """ëª¨ë¸ê³¼ í† í° ìˆ˜ì— ë”°ë¥¸ ê°€ê²© ì •ë³´ ë°˜í™˜"""
        # Claude Sonnet 4 ëª¨ë¸ì˜ ê²½ìš° ê¸°ë³¸ ê°€ê²© ì‚¬ìš©
        if self.is_claude_sonnet_4:
            pricing = self.pricing["claude-sonnet-4"]
        else:
            pricing = self.pricing[self.model_name]
        
        if self.has_complex_pricing:
            # Claude 3.7 Sonnet ë° Claude Sonnet 4 - ë³µì¡í•œ ê°€ê²© êµ¬ì¡°
            model_display = "Claude 3.7" if self.is_claude_3_7 else "Claude Sonnet 4"
            
            if input_tokens >= pricing["threshold"]:
                return {
                    "input_price": pricing["input_high"],
                    "output_price": pricing["output_high"],
                    "thinking_price": 0.0,
                    "cached_price": pricing["cache_read_high"],  # ìºì‹œ ì½ê¸° ê°€ê²©
                    "cache_write_price": pricing["cache_write_high"],  # ìºì‹œ ì“°ê¸° ê°€ê²©
                    "tier": f"{model_display} High (20ë§Œ+ í† í°)"
                }
            else:
                return {
                    "input_price": pricing["input_low"],
                    "output_price": pricing["output_low"],
                    "thinking_price": 0.0,
                    "cached_price": pricing["cache_read_low"],
                    "cache_write_price": pricing["cache_write_low"],
                    "tier": f"{model_display} Low (20ë§Œ ë¯¸ë§Œ í† í°)"
                }
        
        elif self.is_anthropic:
            # ê¸°íƒ€ Anthropic Claude ëª¨ë¸ë“¤
            return {
                "input_price": pricing["input"],
                "output_price": pricing["output"],
                "thinking_price": 0.0,  # Anthropicì€ í˜„ì¬ thinking tokens ì—†ìŒ
                "cached_price": 0.0,   # ê¸°ë³¸ Claude ëª¨ë¸ë“¤ì€ ìºì‹± ì—†ìŒ
                "tier": f"Claude {self.model_name.split('-')[2] if len(self.model_name.split('-')) > 2 else 'Unknown'}"
            }
        
        elif self.model_name == "gemini-2.5-flash":
            return {
                "input_price": pricing["input"],
                "output_price": pricing["output"],
                "thinking_price": pricing["thinking"],
                "cached_price": pricing["cached"],
                "tier": "Flash"
            }
        
        elif self.model_name == "gemini-2.5-pro":
            # ì…ë ¥ í† í° ìˆ˜ì— ë”°ë¼ ê°€ê²© ê²°ì •
            if input_tokens >= pricing["threshold"]:
                return {
                    "input_price": pricing["input_high"],
                    "output_price": pricing["output_high"],
                    "thinking_price": pricing["thinking"],
                    "cached_price": pricing["cached_high"],
                    "tier": "Pro High (20ë§Œ+ í† í°)"
                }
            else:
                return {
                    "input_price": pricing["input_low"],
                    "output_price": pricing["output_low"],
                    "thinking_price": pricing["thinking"],
                    "cached_price": pricing["cached_low"],
                    "tier": "Pro Low (20ë§Œ ë¯¸ë§Œ í† í°)"
                }
        
        return {}
    
    def calculate_batch_cost(self, response):
        """
        API ì‘ë‹µì—ì„œ í† í° ì‚¬ìš©ëŸ‰ì„ ì¶”ì¶œí•˜ê³  ë¹„ìš©ì„ ê³„ì‚° (Gemini/Anthropic ì§€ì›)
        
        Args:
            response: API ì‘ë‹µ ê°ì²´ (Gemini ë˜ëŠ” Anthropic)
            
        Returns:
            dict: í† í° ì‚¬ìš©ëŸ‰ê³¼ ë¹„ìš© ì •ë³´
        """
        try:
            if self.is_anthropic:
                # Anthropic API ì‘ë‹µ ì²˜ë¦¬
                usage = getattr(response, 'usage', None)
                if usage:
                    input_tokens = getattr(usage, 'input_tokens', 0)
                    output_tokens = getattr(usage, 'output_tokens', 0)
                    thinking_tokens = 0  # Anthropicì€ í˜„ì¬ thinking tokens ì—†ìŒ
                    
                    # Claude 3.7 ë° Claude Sonnet 4ì˜ ê²½ìš° ìºì‹± í† í° ì²˜ë¦¬
                    if self.has_complex_pricing:
                        cache_creation_tokens = getattr(usage, 'cache_creation_input_tokens', 0)
                        cache_read_tokens = getattr(usage, 'cache_read_input_tokens', 0)
                        cached_tokens = cache_read_tokens  # ì½ê¸° ìºì‹œ í† í°
                        cache_write_tokens = cache_creation_tokens  # ì“°ê¸° ìºì‹œ í† í°
                    else:
                        cached_tokens = 0
                        cache_write_tokens = 0
                    
                    total_tokens = input_tokens + output_tokens + cached_tokens + cache_write_tokens
                else:
                    # ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì¶”ì •
                    input_tokens = self._estimate_tokens_from_text("")  # ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” ë³„ë„ë¡œ ì „ë‹¬ë°›ì•„ì•¼ í•¨
                    output_tokens = self._estimate_tokens_from_text(response.content[0].text)
                    thinking_tokens = 0
                    cached_tokens = 0
                    total_tokens = input_tokens + output_tokens
            else:
                # Gemini API ì‘ë‹µ ì²˜ë¦¬
                usage_metadata = getattr(response, 'usage_metadata', None)
                
                if usage_metadata:
                    input_tokens = getattr(usage_metadata, 'prompt_token_count', 0)
                    output_tokens = getattr(usage_metadata, 'candidates_token_count', 0)
                    cached_tokens = getattr(usage_metadata, 'cached_content_token_count', 0)
                    thinking_tokens = getattr(usage_metadata, 'reasoning_tokens', 0)
                    total_tokens = getattr(usage_metadata, 'total_token_count', 
                                         input_tokens + output_tokens + thinking_tokens + cached_tokens)
                else:
                    # ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° í…ìŠ¤íŠ¸ ê¸¸ì´ë¡œ ëŒ€ëµ ì¶”ì •
                    input_tokens = self._estimate_tokens_from_text("")  # ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” ë³„ë„ë¡œ ì „ë‹¬ë°›ì•„ì•¼ í•¨
                    output_tokens = self._estimate_tokens_from_text(response.text)
                    thinking_tokens = 0
                    cached_tokens = 0
                    total_tokens = input_tokens + output_tokens
            
            # ëª¨ë¸ë³„ ê°€ê²© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            pricing = self.get_model_pricing(input_tokens)
            
            # ë¹„ìš© ê³„ì‚°
            input_cost = (input_tokens / 1_000_000) * pricing["input_price"]
            output_cost = (output_tokens / 1_000_000) * pricing["output_price"]
            thinking_cost = (thinking_tokens / 1_000_000) * pricing["thinking_price"]
            cached_cost = (cached_tokens / 1_000_000) * pricing["cached_price"]
            
            # Claude 3.7 ë° Claude Sonnet 4ì˜ ê²½ìš° ìºì‹œ ì“°ê¸° ë¹„ìš© ì¶”ê°€
            if self.has_complex_pricing and 'cache_write_tokens' in locals():
                cache_write_cost = (cache_write_tokens / 1_000_000) * pricing.get("cache_write_price", 0)
            else:
                cache_write_cost = 0
                cache_write_tokens = 0
            
            batch_cost = input_cost + output_cost + thinking_cost + cached_cost + cache_write_cost
            
            # ëˆ„ì  í†µê³„ ì—…ë°ì´íŠ¸ (ìŠ¤ë ˆë“œ ì•ˆì „)
            with self._lock:
                self.total_input_tokens += input_tokens
                self.total_output_tokens += output_tokens
                self.total_thinking_tokens += thinking_tokens
                self.total_cached_tokens += cached_tokens
                if self.has_complex_pricing and 'cache_write_tokens' in locals():
                    self.total_cache_write_tokens += cache_write_tokens
                self.total_cost += batch_cost
            
            result = {
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'thinking_tokens': thinking_tokens,
                'cached_tokens': cached_tokens,
                'total_tokens': total_tokens,
                'input_cost': input_cost,
                'output_cost': output_cost,
                'thinking_cost': thinking_cost,
                'cached_cost': cached_cost,
                'batch_cost': batch_cost,
                'pricing_tier': pricing["tier"],
                'model_name': self.model_name
            }
            
            # Claude 3.7 ë° Claude Sonnet 4ì˜ ê²½ìš° ìºì‹œ ì“°ê¸° ì •ë³´ ì¶”ê°€
            if self.has_complex_pricing and 'cache_write_tokens' in locals():
                result['cache_write_tokens'] = cache_write_tokens
                result['cache_write_cost'] = cache_write_cost
            
            return result
            
        except Exception as e:
            print(f"í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒì‹œ í…ìŠ¤íŠ¸ ê¸¸ì´ë¡œ ì¶”ì •
            estimated_output_tokens = self._estimate_tokens_from_text(response.text)
            pricing = self.get_model_pricing(0)  # ê¸°ë³¸ ê°€ê²©ìœ¼ë¡œ ì¶”ì •
            estimated_cost = (estimated_output_tokens / 1_000_000) * pricing["output_price"]
            
            with self._lock:
                self.total_output_tokens += estimated_output_tokens
                self.total_cost += estimated_cost
            
            return {
                'input_tokens': 0,
                'output_tokens': estimated_output_tokens,
                'thinking_tokens': 0,
                'cached_tokens': 0,
                'total_tokens': estimated_output_tokens,
                'input_cost': 0.0,
                'output_cost': estimated_cost,
                'thinking_cost': 0.0,
                'cached_cost': 0.0,
                'batch_cost': estimated_cost,
                'pricing_tier': pricing["tier"],
                'model_name': self.model_name,
                'estimated': True
            }
    
    def _estimate_tokens_from_text(self, text):
        """í…ìŠ¤íŠ¸ ê¸¸ì´ë¡œ í† í° ìˆ˜ ì¶”ì • (1í† í° â‰ˆ 4ë¬¸ì)"""
        if not text:
            return 0
        return len(text) // 4
    
    def get_total_cost_summary(self):
        """ì „ì²´ ëˆ„ì  ë¹„ìš© ìš”ì•½ ë°˜í™˜ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
        with self._lock:
            # í‰ê·  ê°€ê²© ê³„ì‚° (ì—¬ëŸ¬ ë°°ì¹˜ì—ì„œ ë‹¤ë¥¸ ê°€ê²©ëŒ€ê°€ ì ìš©ë  ìˆ˜ ìˆìŒ)
            avg_pricing = self.get_model_pricing(self.total_input_tokens)
            
            summary = {
                'model_name': self.model_name,
                'pricing_tier': avg_pricing["tier"],
                'total_input_tokens': self.total_input_tokens,
                'total_output_tokens': self.total_output_tokens,
                'total_thinking_tokens': self.total_thinking_tokens,
                'total_cached_tokens': self.total_cached_tokens,
                'total_tokens': (self.total_input_tokens + self.total_output_tokens + 
                               self.total_thinking_tokens + self.total_cached_tokens),
                'total_input_cost': (self.total_input_tokens / 1_000_000) * avg_pricing["input_price"],
                'total_output_cost': (self.total_output_tokens / 1_000_000) * avg_pricing["output_price"],
                'total_thinking_cost': (self.total_thinking_tokens / 1_000_000) * avg_pricing["thinking_price"],
                'total_cached_cost': (self.total_cached_tokens / 1_000_000) * avg_pricing["cached_price"],
                'total_cost': self.total_cost
            }
            
            # Claude 3.7 ë° Claude Sonnet 4ì˜ ê²½ìš° ìºì‹œ ì“°ê¸° ì •ë³´ ì¶”ê°€
            if self.has_complex_pricing:
                summary['total_cache_write_tokens'] = self.total_cache_write_tokens
                summary['total_cache_write_cost'] = (self.total_cache_write_tokens / 1_000_000) * avg_pricing.get("cache_write_price", 0)
                summary['total_tokens'] += self.total_cache_write_tokens
            
            return summary
    
    def print_batch_cost(self, batch_id, cost_info):
        """ë°°ì¹˜ë³„ ë¹„ìš© ì •ë³´ ì¶œë ¥"""
        estimated_text = " (ì¶”ì •)" if cost_info.get('estimated', False) else ""
        model_info = f" [{cost_info.get('model_name', 'Unknown')} - {cost_info.get('pricing_tier', 'Unknown')}]"
        
        print(f"ğŸ’° ë°°ì¹˜ {batch_id} í† í° ì‚¬ìš©ëŸ‰{estimated_text}{model_info}:")
        print(f"   ğŸ“¥ ì…ë ¥: {cost_info['input_tokens']:,} í† í° (${cost_info['input_cost']:.6f})")
        print(f"   ğŸ“¤ ì¶œë ¥: {cost_info['output_tokens']:,} í† í° (${cost_info['output_cost']:.6f})")
        
        if cost_info.get('thinking_tokens', 0) > 0:
            print(f"   ğŸ¤” ì‚¬ê³ : {cost_info['thinking_tokens']:,} í† í° (${cost_info['thinking_cost']:.6f})")
        
        if cost_info.get('cached_tokens', 0) > 0:
            print(f"   ğŸ’¾ ìºì‹œ ì½ê¸°: {cost_info['cached_tokens']:,} í† í° (${cost_info['cached_cost']:.6f})")
        
        if cost_info.get('cache_write_tokens', 0) > 0:
            print(f"   âœï¸ ìºì‹œ ì“°ê¸°: {cost_info['cache_write_tokens']:,} í† í° (${cost_info['cache_write_cost']:.6f})")
        
        print(f"   ğŸ’µ ë°°ì¹˜ ì´ ë¹„ìš©: ${cost_info['batch_cost']:.6f} (â‚©{cost_info['batch_cost'] * 1400:.2f})")
    
    def print_total_cost_summary(self):
        """ì „ì²´ ë¹„ìš© ìš”ì•½ ì¶œë ¥"""
        summary = self.get_total_cost_summary()
        
        print(f"\n{'='*60}")
        print(f"ğŸ’° ì „ì²´ ë¹„ìš© ìš”ì•½ [{summary['model_name']} - {summary['pricing_tier']}]")
        print(f"{'='*60}")
        print(f"ğŸ“Š ì´ í† í° ì‚¬ìš©ëŸ‰: {summary['total_tokens']:,} í† í°")
        print(f"   ğŸ“¥ ì…ë ¥ í† í°: {summary['total_input_tokens']:,} (${summary['total_input_cost']:.6f})")
        print(f"   ğŸ“¤ ì¶œë ¥ í† í°: {summary['total_output_tokens']:,} (${summary['total_output_cost']:.6f})")
        
        if summary['total_thinking_tokens'] > 0:
            print(f"   ğŸ¤” ì‚¬ê³  í† í°: {summary['total_thinking_tokens']:,} (${summary['total_thinking_cost']:.6f})")
        
        if summary['total_cached_tokens'] > 0:
            print(f"   ğŸ’¾ ìºì‹œ ì½ê¸° í† í°: {summary['total_cached_tokens']:,} (${summary['total_cached_cost']:.6f})")
        
        if summary.get('total_cache_write_tokens', 0) > 0:
            print(f"   âœï¸ ìºì‹œ ì“°ê¸° í† í°: {summary['total_cache_write_tokens']:,} (${summary['total_cache_write_cost']:.6f})")
        
        print(f"ğŸ’µ ì´ ë¹„ìš©: ${summary['total_cost']:.6f}")
        print(f"ğŸ’µ ì´ ë¹„ìš© (ì›í™”): â‚©{summary['total_cost'] * 1400:.0f} (í™˜ìœ¨ 1,400ì› ê¸°ì¤€)")
        
        # ê°€ê²© ì •ë³´ í‘œì‹œ
        if summary['model_name'] in ["gemini-2.5-pro", "claude-3-7-sonnet"] or 'claude-sonnet-4' in summary['model_name']:
            print(f"\nğŸ“‹ ì ìš©ëœ ê°€ê²© ì •ë³´:")
            pricing = self.get_model_pricing(summary['total_input_tokens'])
            print(f"   ì…ë ¥ í† í°: ${pricing['input_price']:.2f}/1M")
            print(f"   ì¶œë ¥ í† í°: ${pricing['output_price']:.2f}/1M")
            
            if pricing.get('thinking_price', 0) > 0:
                print(f"   ì‚¬ê³  í† í°: ${pricing['thinking_price']:.2f}/1M")
            
            if pricing.get('cached_price', 0) > 0:
                print(f"   ìºì‹œ ì½ê¸°: ${pricing['cached_price']:.3f}/1M")
            
            if pricing.get('cache_write_price', 0) > 0:
                print(f"   ìºì‹œ ì“°ê¸°: ${pricing['cache_write_price']:.2f}/1M")
